This repository demonstrates how to run the Ollama LLM locally inside Google Colab, using the LLAMA3.2 model. It provides a minimal setup for experimenting with LLMs in an interactive cloud environmentâ€”ideal for quick prototyping, natural language querying
